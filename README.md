# DataModeling
The goal of this repo is to give an understanding of how to use pyspark and spark sql to transform raw data to information.Using diffrent techniques as part of the process.This can either be done on AWS EMR using pyspark,HDFS and Apache Hive or On local system having  pyspark,spark sql and local file system,Both these methodologies will be discussed here.

## prerequisite :
* Install pyspark on the local system
* Linux operating system on the local system

## Topics Covered :
* Insights into diffrent types of data sources
* Parsing nested json files using pyspark
* Transfroming data using spark sql
* Constructing a datawarehouse from tranformed data.
* Demo on AWS EMR using Hive as the metastore on HDFS
